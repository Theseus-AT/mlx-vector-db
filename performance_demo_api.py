# performance_demo_api.py
# (Basiert auf Ihrer Datei theseus-at/mlx-vector-db/mlx-vector-db-12319040886f6c23f84935346248ef50cf06157f/performance_demo.py)
"""
Performance Demo f√ºr MLX Vector Database via API-Endpunkte.
Zeigt die Performance-Verbesserungen durch MLX, Caching und optimierte Operationen √ºber die API.
"""
import requests
import time
import numpy as np
import json
import os
import logging # Logging hinzugef√ºgt
# Am Anfang von performance_demo_api.py hinzuf√ºgen:
from typing import Optional
logger = logging.getLogger("mlx_vector_db.perf_demo_api")
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')


BASE_URL = os.getenv("VECTOR_DB_BASE_URL", "http://localhost:8000")
# API_KEY sollte idealerweise als Parameter √ºbergeben oder sicher gehandhabt werden.
# F√ºr dieses Demo-Skript holen wir es aus der Umgebung oder fragen danach.
API_KEY_ENV_VAR = "VECTOR_DB_API_KEY"


def wait_for_server(base_url_to_check: str, timeout_seconds: int = 30):
    """Wartet, bis der Server unter der angegebenen URL erreichbar ist."""
    logger.info(f"üîç √úberpr√ºfe Server-Verf√ºgbarkeit unter {base_url_to_check}...")
    start_time = time.time()
    while True:
        if time.time() - start_time > timeout_seconds:
            logger.error(f"‚ùå Server nicht erreichbar nach {timeout_seconds} Sekunden.")
            raise TimeoutError(f"Server {base_url_to_check} nicht erreichbar nach {timeout_seconds}s")
        try:
            # Verwende einen einfachen Health-Endpunkt, falls vorhanden
            response = requests.get(f"{base_url_to_check}/health", timeout=2)
            if response.status_code == 200:
                logger.info("‚úÖ Server ist bereit!")
                return
        except requests.exceptions.RequestException:
            pass # Einfach weiter versuchen
        time.sleep(1)

def get_api_key_for_demo() -> Optional[str]:
    """Holt den API-Key f√ºr die Demo."""
    api_key = os.getenv(API_KEY_ENV_VAR)
    if not api_key:
        logger.warning(f"{API_KEY_ENV_VAR} nicht in Umgebungsvariablen gefunden.")
        # In einer automatisierten Umgebung sollte hier kein input() sein.
        # F√ºr manuelle Demo-Ausf√ºhrung ist es ok.
        # api_key = input("API Key eingeben (aus .env oder Konfiguration): ").strip()
        # if not api_key:
        #     logger.warning("Kein API-Key angegeben. Versuche Demos ohne Authentifizierung (kann fehlschlagen).")
        #     return None
        logger.warning("Kein API-Key in Umgebungsvariablen. Authentifizierte Endpunkte k√∂nnten fehlschlagen.")
        return None # Besser None zur√ºckgeben, wenn nicht gesetzt
    return api_key

def create_test_store_api(user_id: str, model_id: str, api_key: Optional[str]):
    """Erstellt einen Test-Store √ºber die API."""
    headers = {"Content-Type": "application/json"}
    if api_key: headers["X-API-Key"] = api_key
    
    admin_url_base = f"{BASE_URL}/admin" # Annahme: Admin Routen haben /admin Pr√§fix

    # Store l√∂schen, falls vorhanden (f√ºr sauberen Testlauf)
    try:
        delete_payload = {"user_id": user_id, "model_id": model_id}
        # Die Admin-Route zum L√∂schen ist /admin/store (DELETE)
        requests.delete(f"{admin_url_base}/store", json=delete_payload, headers=headers, timeout=10)
        logger.info(f"Vorheriger Store {user_id}/{model_id} (falls existent) gel√∂scht.")
    except Exception:
        pass # Ignoriere Fehler, wenn Store nicht existiert
    
    # Store erstellen
    create_payload = {"user_id": user_id, "model_id": model_id}
    response = requests.post(f"{admin_url_base}/create_store", json=create_payload, headers=headers, timeout=10)
    response.raise_for_status() # Wirft Fehler bei nicht-2xx Status
    
    logger.info(f"‚úÖ Test-Store √ºber API erstellt: {user_id}/{model_id}")


def run_performance_demo(): # Dies ist die Hauptfunktion f√ºr diese Demo
    """F√ºhrt die API-Performance-Demonstration durch."""
    logger.info("üöÄ MLX Vector Database API Performance Demo")
    logger.info(f"üî• Ziel-Server: {BASE_URL}")
    logger.info("=" * 60)
    
    try:
        wait_for_server(BASE_URL)
    except TimeoutError:
        logger.error("Demo abgebrochen, da Server nicht erreichbar ist.")
        return

    api_key = get_api_key_for_demo()
    headers = {"Content-Type": "application/json"}
    if api_key: headers["X-API-Key"] = api_key
    
    # Performance-Endpunkte (Annahme: /performance Pr√§fix)
    perf_url_base = f"{BASE_URL}/performance"

    logger.info("\n1Ô∏è‚É£ Performance Health Check (API)")
    try:
        response = requests.get(f"{perf_url_base}/health", headers=headers, timeout=5)
        response.raise_for_status()
        health = response.json()
        logger.info(f"   Status: {health.get('status')}")
        logger.info(f"   MLX Version: {health.get('mlx_version', 'unbekannt')}")
        logger.info(f"   Cache Status: {health.get('cache_status', 'unbekannt')}")
    except Exception as e:
        logger.error(f"   ‚ùå Health Check Fehler: {e}")
        return # Demo hier abbrechen, wenn Basis-Checks fehlschlagen

    logger.info("\n2Ô∏è‚É£ Aufw√§rmen der MLX-Funktionen √ºber API...")
    try:
        # Der Warmup-Endpunkt erwartet `dimension` als Query-Parameter
        response = requests.post(f"{perf_url_base}/warmup?dimension=384", headers=headers, timeout=60) # L√§ngerer Timeout f√ºr Warmup
        response.raise_for_status()
        warmup_data = response.json()
        logger.info(f"   ‚úÖ Aufw√§rmen abgeschlossen in {warmup_data.get('warmup_time_seconds', 0):.3f}s")
    except Exception as e:
        logger.warning(f"   ‚ö†Ô∏è Fehler beim Aufw√§rmen: {e}")

    user_id_perf = "api_perf_user"
    model_id_perf = "api_perf_model"
    vector_dim_perf = 384

    logger.info("\n3Ô∏è‚É£ Testumgebung √ºber API einrichten...")
    try:
        create_test_store_api(user_id_perf, model_id_perf, api_key)
    except Exception as e:
        logger.error(f"   ‚ùå Fehler beim Erstellen des Test-Stores √ºber API: {e}")
        return

    logger.info("\n4Ô∏è‚É£ Test-Vektoren √ºber API hinzuf√ºgen...")
    # Ihre Admin-Route /admin/add_test_vectors wird hier verwendet
    vector_count_add = 5000
    try:
        vectors_np = np.random.rand(vector_count_add, vector_dim_perf).astype(np.float32)
        metadata_add = [{"id": f"api_vec_{i}"} for i in range(vector_count_add)]
        add_payload = {
            "user_id": user_id_perf, "model_id": model_id_perf,
            "vectors": vectors_np.tolist(), "metadata": metadata_add
        }
        start_add_api = time.time()
        # Endpunkt /admin/add_test_vectors
        response = requests.post(f"{BASE_URL}/admin/add_test_vectors", json=add_payload, headers=headers, timeout=60)
        response.raise_for_status()
        add_time_api = time.time() - start_add_api
        logger.info(f"   ‚úÖ {vector_count_add} Vektoren hinzugef√ºgt in {add_time_api:.3f}s "
                    f"({vector_count_add/add_time_api:.1f} Vektoren/s √ºber API)")
    except Exception as e:
        logger.error(f"   ‚ùå Fehler beim Hinzuf√ºgen der Vektoren √ºber API: {e}")
        return

    logger.info("\n5Ô∏è‚É£ API Performance Benchmark ausf√ºhren...")
    # Endpunkt /performance/benchmark
    benchmark_payload = {
        "user_id": user_id_perf, "model_id": model_id_perf,
        "test_size": 1000, "query_count": 100, "vector_dim": vector_dim_perf
    }
    try:
        response = requests.post(f"{perf_url_base}/benchmark", json=benchmark_payload, headers=headers, timeout=120) # L√§ngerer Timeout
        response.raise_for_status()
        results = response.json()
        logger.info("\nüìä API BENCHMARK ERGEBNISSE:")
        logger.info(json.dumps(results, indent=2)) # Gibt die vollen Ergebnisse aus
        
        # Wichtige Metriken hervorheben
        summary = results.get("summary", {})
        improvement = summary.get("performance_improvement", {})
        logger.info(f"   üöÄ Gesamt-Speedup (Query): {improvement.get('query_speedup', 'N/A'):.1f}x")
        logger.info(f"   üìà Gesch√§tzte Kapazit√§t: {improvement.get('estimated_capacity', 'N/A')}")

    except Exception as e:
        logger.error(f"   ‚ùå API Benchmark Fehler: {e}")

    # Optional: Store Optimierung √ºber API testen, falls implementiert und gew√ºnscht
    # logger.info("\n6Ô∏è‚É£ Store Optimierung √ºber API...")
    # try:
    #     response = requests.post(f"{perf_url_base}/optimize?user_id={user_id_perf}&model_id={model_id_perf}", headers=headers, timeout=60)
    # ...

    logger.info("\nüßπ Aufr√§umen des Test-Stores √ºber API...")
    try:
        delete_payload = {"user_id": user_id_perf, "model_id": model_id_perf}
        requests.delete(f"{BASE_URL}/admin/store", json=delete_payload, headers=headers, timeout=10)
        logger.info(f"   ‚úÖ Test-Store {user_id_perf}/{model_id_perf} gel√∂scht.")
    except Exception as e:
        logger.warning(f"   ‚ö†Ô∏è Fehler beim Aufr√§umen des Test-Stores: {e}")

    logger.info(f"\nüéâ API Performance Demo abgeschlossen!")

if __name__ == "__main__":
    run_performance_demo()