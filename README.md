# ğŸ§  MLX Vector Database fÃ¼r Apple Silicon

**High-Performance Vector Database optimiert fÃ¼r Apple Silicon mit MLX 0.25.2**

MLXVectorDB ist eine native Apple Silicon Vector Database, die das MLX Machine Learning Framework nutzt fÃ¼r maximale Performance auf M-Series Chips. Entwickelt fÃ¼r lokale RAG-Systeme, Multi-User-Umgebungen und datenschutzfreundliche AI-Anwendungen.

## ğŸš€ Schnellstart

### **Voraussetzungen**
```bash
# Apple Silicon (M1, M2, M3, etc.)
uname -p  # sollte "arm" ausgeben

# macOS 13.5+ (empfohlen: macOS 14+)
sw_vers

# Python 3.9-3.12 (native ARM64)
python -c "import platform; print(platform.processor())"  # sollte "arm" sein
```

### **Installation**
```bash
# Repository klonen
git clone <your-repository-url>
cd mlx-vector-db

# MLX installieren
pip install mlx>=0.25.2

# Core Dependencies installieren
pip install -r requirements.txt

# Konfiguration
cp .env.example .env
# API Key in .env setzen: VECTOR_DB_API_KEY=your-secure-key
```

### **Server starten**
```bash
# Server starten
python main.py

# API Dokumentation Ã¶ffnen
open http://localhost:8000/docs
```

### **Ersten Test ausfÃ¼hren**
```bash
# Einfacher Funktionstest
python simple_test.py

# VollstÃ¤ndiger Test
python working_test_fixed.py

# Sprint 3 Demo (mit allen Features)
python sprint3_demo.py
```

---

## ğŸŒŸ Features

### **ğŸš€ Apple Silicon Optimiert**
* **MLX 0.25.2**: Native Apple Machine Learning Framework
* **Unified Memory**: Zero-copy Operationen zwischen CPU/GPU
* **Metal Kernels**: GPU-Beschleunigung mit Kernel-Caching
* **Lazy Evaluation**: Arrays werden nur bei Bedarf materialisiert
* **ARM64 Native**: Maximale Hardware-Ausnutzung

### **âš¡ High-Performance**
* **1000+ vectors/sec**: Vector Addition Rate
* **100+ QPS**: Query Performance (optimierbar auf 1000+ QPS)
* **Sub-10ms Latency**: Einzelne Queries
* **Batch Processing**: Effiziente Multi-Query Verarbeitung
* **MLX Compilation**: JIT-optimierte Operationen

### **ğŸ—ï¸ Production-Ready**
* **FastAPI REST API**: Async, OpenAPI dokumentiert
* **Rate Limiting**: Intelligente Request-Kontrolle
* **Multi-Store Support**: Separate Stores fÃ¼r User/Modelle
* **Authentication**: API-Key basierte Sicherheit
* **Error Handling**: Graceful Degradation
* **Python SDK**: Async Client mit One-liner Methods

### **ğŸ”’ PrivatsphÃ¤re & Kontrolle**
* **100% Lokal**: Alle Daten bleiben auf dem System
* **Keine Cloud-AbhÃ¤ngigkeit**: Komplett offline betreibbar
* **Metadaten-Filterung**: PrÃ¤zise Suchkriterien
* **Multi-Tenant**: Sichere User-Isolation

---

## ğŸ“Š Performance Benchmarks

**Aktuelle Performance (Korrigierte Version):**
```
ğŸ§  MLX Framework: 0.25.2
âš¡ Vector Addition: 1000+ vectors/sec
ğŸ” Query Performance: 100+ QPS  
ğŸ’¾ Latency: <10ms average
ğŸ¯ Success Rate: >99%
```

---

## ğŸ› ï¸ API Ãœbersicht

### **Core Endpoints**
- `POST /vectors/add` - Vektoren hinzufÃ¼gen
- `POST /vectors/query` - Similarity Search
- `POST /vectors/batch_query` - Batch Queries
- `GET /vectors/count` - Store Statistiken

### **Admin Endpoints**
- `POST /admin/create_store` - Store Management
- `DELETE /admin/store` - Store lÃ¶schen
- `GET /admin/store/stats` - Store Statistiken
- `GET /admin/list_stores` - Alle Stores auflisten

### **Monitoring Endpoints**
- `GET /health` - Service Health
- `GET /performance/health` - Performance Status
- `GET /monitoring/metrics` - System Metriken
- `GET /system/info` - System Information

**VollstÃ¤ndige API-Dokumentation:** http://localhost:8000/docs

---

## ğŸ”§ Erste Schritte

### **1. Einfacher Test**
```bash
python simple_test.py
```
FÃ¼hrt grundlegende FunktionalitÃ¤tstests durch und Ã¼berprÃ¼ft, ob alles korrekt funktioniert.

### **2. Store erstellen und verwenden**
```python
import requests
import numpy as np

BASE_URL = "http://localhost:8000"
API_KEY = "mlx-vector-dev-key-2024"
headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}

# Store erstellen
create_payload = {"user_id": "my_user", "model_id": "my_model", "dimension": 384}
response = requests.post(f"{BASE_URL}/admin/create_store", json=create_payload, headers=headers)

# Vektoren hinzufÃ¼gen
vectors = np.random.rand(100, 384).astype(np.float32)
metadata = [{"id": f"doc_{i}", "text": f"Document {i}"} for i in range(100)]

add_payload = {
    "user_id": "my_user",
    "model_id": "my_model", 
    "vectors": vectors.tolist(),
    "metadata": metadata
}
response = requests.post(f"{BASE_URL}/vectors/add", json=add_payload, headers=headers)

# Vektoren abfragen
query_vector = vectors[0].tolist()
query_payload = {
    "user_id": "my_user",
    "model_id": "my_model",
    "query": query_vector,
    "k": 5
}
response = requests.post(f"{BASE_URL}/vectors/query", json=query_payload, headers=headers)
results = response.json()
```

### **3. Python SDK verwenden**
```python
import asyncio
from sdk.python.mlx_vector_client import create_client

async def main():
    async with create_client("http://localhost:8000", api_key="mlx-vector-dev-key-2024") as client:
        # Store erstellen
        await client.create_store("my_user", "my_model", dimension=384)
        
        # Einfache Text-Embeddings hinzufÃ¼gen
        texts = ["Machine learning is amazing", "Vector search is powerful"]
        embeddings = [[0.1] * 384, [0.2] * 384]  # Ihre echten Embeddings hier
        
        await client.quick_add("my_user", "my_model", texts, embeddings)
        
        # Semantic Search
        results = await client.quick_search("my_user", "my_model", embeddings[0], k=5)
        print("Search results:", results)

asyncio.run(main())
```

---

## ğŸ“ Datenstruktur

```
~/.team_mind_data/vector_stores/
â”œâ”€â”€ user_{id}/
â”‚   â””â”€â”€ {model_name}/
â”‚       â”œâ”€â”€ vectors.npz          # MLX-optimierte Vektoren
â”‚       â””â”€â”€ metadata.jsonl       # ZugehÃ¶rige Metadaten  
```

**MLX NPZ Format:** Nutzt MLX native serialization fÃ¼r maximale Performance

---

## ğŸ”§ Entwicklung & Testing

### **Tests ausfÃ¼hren**
```bash
# Einfacher Funktionstest
python simple_test.py

# VollstÃ¤ndiger API-Test
python working_test_fixed.py

# Sprint 3 Demo (alle Features)
python sprint3_demo.py

# Unit Tests (falls verfÃ¼gbar)
pytest tests/ -v
```

### **Performance Demo**
```bash
# Basis Demo
python demo.py

# Performance-spezifische Tests
python performance_demo.py
```

### **Debugging**
```bash
# MLX Status prÃ¼fen
python -c "
import mlx.core as mx
print('MLX Version:', mx.__version__)
test = mx.random.normal((10, 384))
mx.eval(test)  
print('âœ… MLX working!')
"

# Server Debug-Info (nur Development)
curl http://localhost:8000/debug/mlx
curl http://localhost:8000/debug/routes
```

---

## ğŸš¨ Troubleshooting

### **HÃ¤ufige Probleme**

#### **MLX Import Fehler**
```bash
# LÃ¶sung: MLX neu installieren
pip uninstall mlx
pip install mlx>=0.25.2

# Verify Installation
python -c "import mlx.core as mx; print(mx.default_device())"
```

#### **Server startet nicht**
```bash
# Ports prÃ¼fen
lsof -i :8000

# Dependencies prÃ¼fen
pip install -r requirements.txt

# Logs prÃ¼fen
python main.py 2>&1 | tee server.log
```

#### **API Authentifizierung Fehler**
```bash
# .env Datei prÃ¼fen
cat .env

# API Key in Environment setzen
export VECTOR_DB_API_KEY=mlx-vector-dev-key-2024

# Test mit curl
curl -H "Authorization: Bearer mlx-vector-dev-key-2024" http://localhost:8000/health
```

#### **Performance Probleme**
```bash
# System Resources prÃ¼fen
python -c "
import psutil
print('Memory:', psutil.virtual_memory().percent, '%')
print('CPU:', psutil.cpu_percent(), '%')
"

# MLX Device prÃ¼fen
python -c "
import mlx.core as mx
print('Device:', mx.default_device())
"
```

### **Support**
- **Issues:** GitHub Issues fÃ¼r Bugs und Feature Requests
- **Tests:** `python simple_test.py` fÃ¼r grundlegende FunktionalitÃ¤t
- **Performance:** `python working_test_fixed.py` fÃ¼r vollstÃ¤ndige Tests
- **Logs:** Server Logs unter `/logs/` (wenn konfiguriert)

---

## ğŸ¯ Roadmap

### **Phase 1: Core Stability (âœ… Completed)**
- [x] MLX 0.25.2 Integration
- [x] FastAPI REST API
- [x] Basic Vector Operations
- [x] Authentication System
- [x] Error Handling & Recovery

### **Phase 2: Production Features (âœ… Completed)**
- [x] Rate Limiting
- [x] Python SDK
- [x] Batch Operations
- [x] Performance Monitoring
- [x] Health Checks

### **Phase 3: Advanced Features (ğŸš§ In Progress)**
- [x] MLX-LM Integration (Basic)
- [x] RAG Pipeline (Simplified)
- [x] Text Processing (Mock/Fallback)
- [ ] HNSW Indexing (Planned)
- [ ] Advanced Caching (Planned)

### **Phase 4: Enterprise (ğŸ“‹ Planned)**
- [ ] Distributed Storage
- [ ] Advanced Security
- [ ] Real-time Analytics
- [ ] Auto-scaling

---

## ğŸ“¦ Dependencies

### **Core Requirements**
```
mlx>=0.25.2
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.0.0
numpy>=1.26.0
psutil>=5.9.0
```

### **Optional Dependencies**
```bash
# FÃ¼r MLX-LM Integration
pip install mlx-lm sentence-transformers

# FÃ¼r erweiterte Features
pip install matplotlib tqdm

# FÃ¼r Tests
pip install pytest pytest-asyncio httpx
```

---

## ğŸ—ï¸ Architektur

```
MLX Vector Database
â”œâ”€â”€ main.py                     # FastAPI Application
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ vectors.py         # Core Vector Operations
â”‚   â”‚   â”œâ”€â”€ admin.py           # Store Management
â”‚   â”‚   â”œâ”€â”€ performance.py     # Performance Endpoints
â”‚   â”‚   â””â”€â”€ monitoring.py      # Health & Monitoring
â”‚   â””â”€â”€ middleware/
â”‚       â””â”€â”€ rate_limiting.py   # Rate Limiting Logic
â”œâ”€â”€ service/
â”‚   â”œâ”€â”€ optimized_vector_store.py  # MLX Vector Store
â”‚   â””â”€â”€ models.py              # Pydantic Models
â”œâ”€â”€ sdk/python/
â”‚   â””â”€â”€ mlx_vector_client.py   # Python SDK
â”œâ”€â”€ integrations/
â”‚   â””â”€â”€ mlx_lm_pipeline.py     # MLX-LM Integration
â”œâ”€â”€ security/
â”‚   â””â”€â”€ auth.py                # Authentication
â””â”€â”€ tests/
    â”œâ”€â”€ simple_test.py         # Basic Functionality
    â”œâ”€â”€ working_test_fixed.py  # Complete API Tests
    â””â”€â”€ sprint3_demo.py        # Feature Demo
```

---

## ğŸ” Sicherheit

### **Production Deployment**
```bash
# Environment Variables setzen
export VECTOR_DB_API_KEY=your-secure-api-key
export VECTOR_DB_ADMIN_KEY=your-admin-key
export ENVIRONMENT=production

# Production Server starten
python main.py production
```

### **API Keys**
- **Development:** `mlx-vector-dev-key-2024` (Standard)
- **Production:** Eigene sichere Keys verwenden
- **Admin Operations:** Separate Admin-Keys fÃ¼r kritische Operationen

### **Best Practices**
- API Keys niemals in Code committen
- `.env` Dateien zu `.gitignore` hinzufÃ¼gen
- Rate Limiting in Production aktivieren
- Health Checks fÃ¼r Monitoring einrichten

---

## ğŸš€ Produktions-Deployment

### **Docker Deployment**
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["python", "main.py", "production"]
```

### **Systemd Service**
```ini
[Unit]
Description=MLX Vector Database
After=network.target

[Service]
Type=simple
User=mlxvector
WorkingDirectory=/opt/mlx-vector-db
Environment=ENVIRONMENT=production
ExecStart=/opt/mlx-vector-db/venv/bin/python main.py production
Restart=always

[Install]
WantedBy=multi-user.target
```

---

## ğŸ“ˆ Performance Tuning

### **MLX Optimierungen**
```python
# In optimized_vector_store.py
config = MLXVectorStoreConfig(
    jit_compile=True,          # JIT Compilation aktivieren
    use_metal=True,            # Metal GPU nutzen
    enable_lazy_eval=True,     # Lazy Evaluation
    max_cache_vectors=10000,   # Vector Caching
    batch_size=1000           # Optimale Batch-GrÃ¶ÃŸe
)
```

### **System Tuning**
```bash
# Memory fÃ¼r MLX optimieren
export MLX_MEMORY_POOL_SIZE=2GB

# Metal Performance Shaders
export METAL_DEVICE_WRAPPER_TYPE=1

# System Limits erhÃ¶hen
ulimit -n 65536
```

---

## ğŸ“š Weitere Ressourcen

### **MLX Framework**
- [MLX GitHub](https://github.com/ml-explore/mlx)
- [MLX-LM Examples](https://github.com/ml-explore/mlx-lm)
- [MLX Documentation](https://ml-explore.github.io/mlx/build/html/)

### **Beispiel-Integrationen**
- **Embedding Models:** sentence-transformers, E5, BGE
- **Vector Search:** Semantic Search, RAG Pipelines
- **Text Processing:** Document Chunking, Metadata Extraction

### **Community**
- **Issues:** Bug Reports und Feature Requests via GitHub
- **Discussions:** FÃ¼r Fragen und Diskussionen
- **Contributions:** Pull Requests willkommen!

---

## ğŸ“œ Lizenz

Apache License 2.0 - siehe [LICENSE](LICENSE) Datei.

---

## ğŸ† Acknowledgments

* **Apple MLX Team** - FÃ¼r das fantastische ML Framework
* **FastAPI Community** - FÃ¼r das moderne Web Framework  
* **NumPy Ecosystem** - FÃ¼r die Array-Computing Basis

---

**ğŸ Optimiert fÃ¼r Apple Silicon â€¢ ğŸš€ Powered by MLX 0.25.2**

## ğŸ¯ NÃ¤chste Schritte

1. **Erste Tests:** `python simple_test.py`
2. **VollstÃ¤ndige Demo:** `python sprint3_demo.py`  
3. **Eigene Integration:** SDK verwenden oder REST API direkt nutzen
4. **Production:** Environment Variables setzen und optimieren
5. **Erweiterte Features:** MLX-LM Dependencies installieren fÃ¼r vollstÃ¤ndige Text-Pipeline